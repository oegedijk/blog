<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Introducing explainerdashboard | Data science explained</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Introducing explainerdashboard" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="quickly deploying explainable AI dashboards" />
<meta property="og:description" content="quickly deploying explainable AI dashboards" />
<link rel="canonical" href="https://oegedijk.github.io/blog/markdown/2020/10/15/introducing-explainerdashboard.html" />
<meta property="og:url" content="https://oegedijk.github.io/blog/markdown/2020/10/15/introducing-explainerdashboard.html" />
<meta property="og:site_name" content="Data science explained" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-15T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"quickly deploying explainable AI dashboards","@type":"BlogPosting","url":"https://oegedijk.github.io/blog/markdown/2020/10/15/introducing-explainerdashboard.html","dateModified":"2020-10-15T00:00:00-05:00","datePublished":"2020-10-15T00:00:00-05:00","headline":"Introducing explainerdashboard","mainEntityOfPage":{"@type":"WebPage","@id":"https://oegedijk.github.io/blog/markdown/2020/10/15/introducing-explainerdashboard.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://oegedijk.github.io/blog/feed.xml" title="Data science explained" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-21800815-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Introducing explainerdashboard | Data science explained</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Introducing explainerdashboard" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="quickly deploying explainable AI dashboards" />
<meta property="og:description" content="quickly deploying explainable AI dashboards" />
<link rel="canonical" href="https://oegedijk.github.io/blog/markdown/2020/10/15/introducing-explainerdashboard.html" />
<meta property="og:url" content="https://oegedijk.github.io/blog/markdown/2020/10/15/introducing-explainerdashboard.html" />
<meta property="og:site_name" content="Data science explained" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-15T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"quickly deploying explainable AI dashboards","@type":"BlogPosting","url":"https://oegedijk.github.io/blog/markdown/2020/10/15/introducing-explainerdashboard.html","dateModified":"2020-10-15T00:00:00-05:00","datePublished":"2020-10-15T00:00:00-05:00","headline":"Introducing explainerdashboard","mainEntityOfPage":{"@type":"WebPage","@id":"https://oegedijk.github.io/blog/markdown/2020/10/15/introducing-explainerdashboard.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://oegedijk.github.io/blog/feed.xml" title="Data science explained" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-21800815-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>



<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Data science explained</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Introducing explainerdashboard</h1><p class="page-description">quickly deploying explainable AI dashboards</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-15T00:00:00-05:00" itemprop="datePublished">
        Oct 15, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><p>As data scientists working in a public or regulated sector we are under increasing pressure to make sure that our machine learning models are transparent, explainable and fair. With the advent of tools such as SHAP and LIME, the old black-box trope actually does not really apply anymore, and it has become quite straightforward to explain how each feature contributed to each individual prediction for example. However straightforward for a data scientist is not the same as straightforward for a manager, supervisor or regulator. And so what is needed is a tool that allows non-technical stakeholders to inspect the workings, performance and predictions of a machine learning model without needing to learn Python or getting the hang of Jupyter notebooks. </p>

<p>With the <code class="highlighter-rouge">explainerdashboard</code> python package, building, deploying and sharing interactive dashboards
that allow non-technical users to explore the inner workings of a machine learning model 
can be done with just two lines of code. For example to build this example hosted at <a href="titanicexplainer.herokuapp.com/classifier">titanicexplainer.herokuapp.com/classifier</a>, you just to 
need to fit a model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">explainerdashboard.datasets</span> <span class="kn">import</span> <span class="n">titanic_survive</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">titanic_survive</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<p>And pass it to an <code class="highlighter-rouge">Explainer</code> object:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">explainerdashboard</span> <span class="kn">import</span> <span class="n">ClassifierExplainer</span>

<span class="n">explainer</span> <span class="o">=</span> <span class="n">ClassifierExplainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<p>And then you simply pass this <code class="highlighter-rouge">explainer</code> to an <code class="highlighter-rouge">ExplainerDashboard</code> and run it:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">explainerdashboard</span> <span class="kn">import</span> <span class="n">ExplainerDashboard</span>
<span class="n">ExplainerDashboard</span><span class="p">(</span><span class="n">explainer</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div></div>

<p>This will launch a dashboard built on top off plotly <code class="highlighter-rouge">dash</code> that will run on
<code class="highlighter-rouge">http://localhost:8050</code> by default.</p>

<p>With this dashboard you can for example see which features are the most 
important to the model:</p>

<p><img src="https://oegedijk.github.io/blog/images/explainerdashboard/tab_importances.png" alt="" title="importances tab"></p>

<!-- 
Or how the model performs:

![](en/latest/_images/tab_model_performance.png "model performance tab")

And you can explain how each individual feature contributed to each
individual prediction:

![](en/latest/_images/tab_individual_predictions.png "contributions tab")

Figure out how predictions would have changed if one or more of the variables
were different:

![](en/latest/_images/tab_whatif.png "whatif tab")

See how feature impact predictions :

![](en/latest/_images/tab_feature_dependence.png "feature dependence tab")


And even inspect every decision tree inside a random forest:

![](en/latest/_images/tab_decision_trees.png "decisiontrees tab")




 -->


  </div><a class="u-url" href="/blog/markdown/2020/10/15/introducing-explainerdashboard.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A blog about data science, explainable AI, python tricks and more</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/oegedijk" title="oegedijk"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/oegedijk" title="oegedijk"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
